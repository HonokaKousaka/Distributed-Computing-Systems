## 第 2 章  Hadoop 文件系统

Hadoop文件系统（HDFS）是 Hadoop 项目的一部分，发起者 Doug Cutting.

HDFS 可以结合 MapReduce 解决超大规模的网页存储和分析处理问题。

**概念辨析**：Hadoop 由 MapReduce 与 HDFS 构成。

### 2.1 设计思想

HDFS 的设计主要是为了解决以下问题：

1. **存储上百 GB/TB 级别的大文件。**（最重要）

2. 保证文件系统的容错。集群由低廉的服务器甚至个人 PC 组成，节点发生故障是普遍现象。
3. 进行大文件的并发读写控制。网页分析的数据处理场景中，大文件的写入和读取往往是并发的。

解决上述问题的思想：

1. **文件分块存储**：HDFS 将大文件切分成（若干大小相同的）块，这些文件块可以分布到集群中不同的节点上。HDFS 采用了分而治之的策略，令多个节点对逻辑层面的大文件在物理层面进行分布式存储。
2. **分块冗余存储**：HDFS 将大文件切分成块，每个小块同时进行冗余备份。由于多个备份会分散到不同的节点上，因此除非存放某一文件块的所有节点均发生故障，否则 HDFS 在部分节点发生故障的情况下依然可以访问该文件块。
3. **简化文件读写**：由于 HDFS 的文件往往一次写入后不再修改而是多次读取，因此 HDFS 简化了文件读写模型，采用“一次写入，多次读取”的方式，即可避免读写冲突。HDFS 仅需支持顺序写入而不支持随机写入。

**不可以修改，因为如果修改的话就需要更新每个机器上的块。也不能随机写入，因为块的大小是固定的，随机写入会导致冲突。**

### 2.2 体系架构

#### 2.2.1 架构图

![image-20240604182240385](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240604182240385.png)

HDFS 采用“主从”架构，由 NameNode, Secondary NameNode, DataNode 构成。**他们的本质都是进程，只是运行在不同的机器上！**

NameNode 所在节点为主节点，Secondary NameNode 所在节点为主节点的备用节点，DataNode 所在节点为从节点。客户端发起文件读写等操作请求。

1. NameNode：负责 HDFS 的管理工作，包括管理文件目录结构、位置等元数据、维护 DataNode 的状态等。**并不实际存储文件。**
2. Secondary NameNode：充当 NameNode 的备份，当 NameNode 发生故障时利用 Secondary NameNode 进行恢复。
3. DataNode：负责存储文件，根据 NameNode 的控制信息存储和管理对应的文件块，定期向 NameNode 汇报自身的状态。（心跳）

![image-20240604183626422](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240604183626422.png)

NameNode 在内存中维护了树形结构的目录，即 HDFS 的目录结构。其中的块信息仅指示了文件块存储的位置，并不实际存储文件。HDFS 将位于内存中的目录结构及其元数据（描述数据的数据）写入磁盘的 FsImage 文件（图 2.3 的树形结构即 FsImage），可以将其视为 HDFS 目录结构的一个本地快照。针对目录及文件的修改操作，除了修改内存中的树目录外，还以日志形式记录到磁盘的 EditLog 中。**FsImage 与 EditLog 均在NameNode的磁盘里。**

![image-20240604184158958](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240604184158958.png)

作为 NameNode 的备份，Secondary NameNode 通常在另一台单独的物理计算机上运行，定期备份 FsImage 和 EditLog 两个文件，合并形成文件目录及其元数据的远程检查点，并将检查点返回给 NameNode。

如果 Secondary NameNode 不请求备份，则任何对数据的修改都是先记录日志，再在内存中对元数据进行修改。

如果 Secondary NameNode 请求了备份，则：

1. 将新到达的修改操作追加到新的日志文件 EditLog.new 中。
2. Secondary NameNode 拉取 NameNode 中的 EditLog 和 FsImage，将两个文件合并形成最新的文件目录结构，形成检查点文件 FsImage.ckpt
3. Secondary NameNode 将检查点文件 FsImage.ckpt 返回给 NameNode
4. NameNode 使用 FsImage.ckpt 替换旧的 FsImage文件，并使用 EditLog.new 替换旧的 EditLog 文件。

数据块的存储于 DataNode 的本地文件系统中。

#### 2.2.2 应用程序执行流程

![image-20240604190952279](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240604190952279.png)

1. 客户端向 NameNode 发起文件操作请求，常见的发起请求的方式为编写 Java 或使用 HDFS Shell。
2. 如果是读写文件操作，则 NameNode 告知客户端文件块存储的位置信息。如果是创建、删除、重命名目录或文件等操作，NameNode 成功修改文件目录结构后即结束该操作。对于删除操作，HDFS 并不会立即删除 DataNode 上的数据块，而是等到特定时间才会删除。**因为删除文件时，文件系统不能做其他任何事。如果我们删除了一个大文件，那么我们有很长一段时间无法执行其他操作，效率很低。**
3. 对于读写文件操作，客户端获知具体位置信息后再与 DataNode 进行读写交互。

### 2.3 工作原理

#### 2.3.1 文件分块与备份

一般地，HDFS 中的每个文件块均设有 3 个副本，在写入文件块时，NameNode 使用以下启发式策略决定副本放置方式。

![image-20240604193718136](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240604193718136.png)

1. 第一个副本：如果客户端和某一 DataNode 位于同一个物理节点，那么 HDFS 将第一个副本放置于该 DataNode；如果客户端不与任何 DataNode 位于同一个物理节点，那么 HDFS 随机挑选一台磁盘容量与 CPU 性能俱佳的节点。该副本放置策略的优点是能够支持快速写入。
2. 第二个副本：NameNode 将第二个副本放置在与第一个副本不同的机架的某一节点上。该副本放置策略有利于整体减少跨机架的网络流量。**因为如果在另一个机架的某个节点要读取该文件块，就可以不用跨机架了。**
3. 第三个副本：NameNode 将第三个副本放置在第一个副本所在的机架的不同节点上。应对故障发生时的文件块读取。

#### 2.3.2 文件写入

![image-20240604194606576](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240604194606576.png)

1. 客户端与 NameNode 通信，请求写入一个文件块。
2. NameNode 根据启发式策略决定文件块放置的 DataNode，将 DataNode 的位置告知客户端。
3. 客户端与 DataNode1 建立连接，DataNode1 与 DataNode2 建立连接，DataNode2 与 DataNode3建立连接，客户端将文件块以流水线的方式写入 DataNode。**先给 DataNode1，再由 DataNode1 进一步传递。**
4. DataNode3 写入完毕后向 DataNode2 发送确认消息，随后 DataNode2 向 DataNode1 发送确认消息。最后，DataNode1 向客户端发送确认消息，表示该文件块成功写入。**接下来可以请求写入下一个文件块，重复上述过程了。因此，单个文件块以流水线方式传输，而文件块之间以一种阻塞方式传输。**

**只能是顺序写。由于节点可能发生故障，无法保证客户端对每个节点的直接写入是可行的，因此文件块之间以阻塞方式传输。**

由于一个块往往为 64 MB 或 128 MB 甚至更大，因此客户端并非将整个文件块一次性传输给 DataNode1，而是以更小（例如 64 KB）的数据包（packet）为单位依次传输。

### 2.3.3 文件读取

![image-20240604195214441](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240604195214441.png)

1. 客户端与 NameNode 通信，请求读取一个文件。
2. NameNode 根据文件的路径等信息判断读取请求是否合法，如果合法则向客户端返回文件中所有数据块的存放地址。
3. 对于第 1 个数据块，客户端从距离最近的存放该数据块的 DataNode 读取数据。
4. 当第 1 个数据块读取完毕后，客户端从距离最近的存放第 2 个数据块的 DataNode 读取数据。
5. 以此类推，直到读取完毕所有的数据块。

**注意，对于一个文件，要读取多个文件块的时候，只能顺序读。如果是读取多个文件，那么是可以并行的。**

#### 2.3.4 文件读写与一致性

虽然可以通过加锁等方式进行互斥访问，但增加了编程的复杂度。

HDFS 采用“一次写入，多次读取”的简化一致性模型。

1. 一个文件经过创建、写入和关闭后即不得改变文件中的已有内容。
2. 若已经写入 HDFS 文件，则仅允许在文件末尾追加数据，即执行 append 操作。
3. 当对一个文件执行写入操作或者追加操作时，NameNode 将拒绝其他针对该文件的读写请求。
4. 当对一个文件执行读取操作时，NameNode 允许其他针对该文件的读请求。

**这避免了读写冲突，用户编程无需考虑文件锁。**

**假如用户的确需要修改已有文件中的内容，只能删除文件，重新写入。**

**如果 HDFS 允许修改文件中的已有内容，保持一致性的操作会非常复杂。**

### 2.4 容错机制

#### 2.4.1 NameNode 故障

根据 Secondary NameNode 中的 FsImage 和 Editlog 数据进行恢复。

（是冷备份，由于他们并不总是同步相同，**可能会造成部分文件修改操作的丢失**）

#### 2.4.2 DataNode 故障

DataNode 定期向 NameNode 发送心跳，以表示该节点处于活跃状态。如果 NameNode 在一定时间范围内没有收到某个 DataNode 的心跳，NameNode 认为该 DataNode 处于宕机状态，DataNode 节点上面的所有数据都会被标为“不可读”，若客户端发起写文件块的请求，NameNode 向客户端提供的可以存储文件块的位置中将不会包含该 DataNode。如果客户端发起读文件块的请求，那么 NameNode 向客户端提供的文件块存储位置中将排除该 DataNode。 

HDFS 中的文件块均拥有若干副本，一旦有 DataNode 发生宕机，则将导致部分文件块的副本数量小于预先设定的副本数量，此时系统需要在其他 DataNode 对该类文件块进行备份以达到预先设定的副本数量。方法是要求一个含有该副本的 DataNode 将该副本复制给另外的不含有该副本的正常的 DataNode 节点，修改 NameNode 中文件块的元数据。



## 第 3 章  批处理系统 MapReduce

通常说的 MapReduce 是 Hadoop 项目中的 MapReduce，是一个分布式计算系统，主要用于处理大批量的静态数据（计算开始前已经确定的数据）。

### 3.1 设计思想

Hadoop 往往被视为第一个大数据项目。但是，在 MapReduce 之前还存在其他分布式计算系统。此前存在的 MPI 等分布式计算系统存在不足，因此催生了 MapReduce 系统。

#### 3.1.1 MPI 与 MapReduce

MPI 是一种消息传递接口 （message passing interface），实际上是一个以 C 语言编写的消息传递函数库的标准说明，提供了分布式环境下的一种并行编程范式。

MPI 只是为程序员提供了一个并行环境库，程序员通过调用 MPI 提供的程序接口达到并行处理的目的。

虽然 MPI 可以达到并行处理数据的目的，但该编程范式存在以下缺点。

1. **用户编程**的角度来看，程序员需要考虑进程之间的并行问题，并且进程之间的通信需要用户在程序中显式地表达，增加了程序员编程的复杂性。
2. **系统实现**的角度来看，MPI 程序以多进程方式运行，如果在运行过程中某一进程因故障而崩溃，那么除非用户在编写程序时添加了故障恢复的功能，否则 MPI 编程框架本身并不提供容错功能。

由于 MPI 无法提供容错，一旦 MPI 程序在运行过程中出现故障而崩溃，则需将该程序重新运行。如果程序运行的时间较长，则意味着计算资源的浪费。为了避免浪费而依赖程序员在编程中加入故障恢复处理功能并不现实。因此，MapReduce 系统与 MPI 的一个重要区别是**分布式计算系统本身需要具备容错能力。**

#### 3.1.2 数据模型

MapReduce 将数据抽象为一系列键值对，在处理过程中对键值对进行转换。MapReduce 的输入为一组键值对，进行转换后的输出也为一组键值对。在用户的编程中，MapReduce 的输入键值对通常来自存储于 HDFS 中的文件，MapReduce 框架从文件中提取一系列键值对。

传统流程：Map，Shuffle，Reduce

![image-20240606193813332](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240606193813332.png)

#### 3.1.3 计算模型

MapReduce 将复杂的、运行于大规模分布式集群中的并行计算过程高度抽象为 Map 和 Reduce 两个过程，采用“分而治之”的策略对数据进行并行处理。

![image-20240606194402809](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240606194402809.png)

从图的角度看，它是一张仅包含两个顶点的有向无环图（DAG）。为了支持大规模的并行处理，两个算子在物理上需要由若干实例实现。此处的实例是指进程或线程。

![image-20240606194607764](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240606194607764.png)

图 3.4 中，4 个进程执行 map 算子中的操作，3 个进程执行 reduce 算子中的操作。

从用户编程的角度看，用户无须像 MPI 编程那样关心分布式系统中节点间的通信方式，而是可以像编写集中式程序那样编写 MapReduce 代码。从系统实现的角度来看，系统可以并行启动一系列进程以执行 Map 和 Reduce 操作，一旦进程出现故障，MapReduce 框架则可自动进行容错处理，无须用户参与。

### 3.2 体系架构

#### 3.2.1 架构图

MapReduce 系统采用“主从”架构，主要工作部件包括 JobTracker, TaskTracker, Task 以及客户端。

1. JobTracker：主节点运行的后台进程，负责整个系统的**资源管理**和**作业管理**。**资源管理**主要是指 JobTracker 通过监控 TaskTracker 管理系统拥有的计算资源，**作业管理**是指 JobTracker 负责将作业（Job）拆分成任务（Task），并进行任务调度以及跟踪任务的运行进度、资源使用量等信息。
2. TaskTracker：从节点运行的后台进程，负责管理本节点的资源、执行 JobTracker 的命令并汇报情况。TaskTracker 使用 slot 等量划分本节点中的资源量（CPU, 内存等），接受 JobTracker 发送的命令并执行（如启动新任务、杀死任务等），通过心跳将本节点的资源使用情况和任务运行进度汇报给 JobTracker。
3. Task：从节点在应用程序执行过程中启动的进程，负责任务执行。JobTracker 根据 TaskTracker 汇报的信息进行调度，命令存在空闲 slot 的 TaskTracker 启动 Task 进程执行 Map 或 Reduce 任务，即 MapTask 或 ReduceTask。在 Hadoop MapReduce 的架构中，该进程的名称是Child。

**这三者的本质是进程。**

4. 客户端：客户端所在节点为提交应用程序启动的进程，负责将用户编写的 MapReduce 程序提交给 JobTracker。在 Hadoop MapReduce 的架构中，该进程的名称是 RunJar。

![image-20240607022053110](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240607022053110.png)

在实际使用中，通常将 MapReduce 的输入和输出数据均存储于 HDFS 中。

注意，Hadoop 项目包含的 MapReduce 和 HDFS 两个子项目本身相对独立，因此其既可以部署在不同的物理节点上，也可以部署在相同的物理节点上。但是，部署在不同物理节点上虽然可以正常工作，但是会导致 MapTask 要从远程的 DataNode 节点读取输入数据，即“数据向计算靠拢”，通过网络读取大批量数据的代价通常较大。ReduceTask 计算得到的结果也需要通过网络写入远程的 DataNode，通过网络写入大批量数据的代价同样较大。

为了避免通过网络读写输入输出的高昂代价，MapReduce 和 HDFS 通常部署于同一组物理节点构成的集群中。JobTracker 和 NameNode 部署在同一个物理节点，而 TaskTracker 和 DataNode 部署在同一个物理节点。MapReduce 可以选择存储输入数据的 DataNode 所在节点启动 MapTask，节省了远程读取数据的网络开销。ReduceTask 的输出数据可以存储于所在节点的 DataNode，避免远程写入的网络开销。该方法使得 MapReduce 在读写输入输出数据时无须通过网络移动数据，体现了“计算向数据靠拢”的理念。可以使用其他分布式文件系统或存储系统替代 HDFS 存储输入输出数据。

![image-20240607101852333](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240607101852333.png)

#### 3.2.2 应用程序执行流程

![image-20240607101947581](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240607101947581.png)

1. 客户端将用户编写的MapReduce作业的配置信息、jar包等信息上传到共享文件系统。通常是HDFS。
2. 客户端提交作业给JobTracker，并告知JobTracker作业信息的位置。
3. JobTracker读取作业的信息，生成一系列Map和Reduce任务，并调度给拥有空闲slot的TaskTracker。
4. TaskTracker根据JobTracker的指令启动Child进程执行Map任务，Map任务从共享文件系统读取输入数据。
5. JobTracker从TaskTracker处获得Map任务进度信息。
6. Map任务完成后，JobTracker将Reduce任务分发给TaskTracker。
7. TaskTracker根据JobTracker的指令启动Child进程执行Reduce任务，Reduce任务从Map任务所在节点的本地磁盘中拉取Map的输出结果。
8. JobTracker从TaskTracker处获得Reduce任务进度信息。
9. Reduce任务运行结束并将结果写入共享文件系统时，整个作业执行完毕。

### 3.3 工作原理

略，因为太细节。

详见课本。

### 3.4 容错机制

#### 3.4.1 JobTracker故障

非常严重。一旦JobTracker发生故障，正在运行的所有作业的内部状态信息将会丢失。

JobTracker发生故障后，需要重新启动JobTracker，所有作业均需重新执行。因此，MapReduce中JobTracker的单节点故障瓶颈是该架构设计的缺陷。（MapReduce 1.0）

#### 3.4.2 TaskTracker故障

JobTracker无法接收TaskTracker发送的心跳，JobTracker会认为该TaskTracker失效。因此，在该TaskTracker所在节点运行过的任务均会被标记为失败，JobTracker将这些任务调度到别的TaskTracker所在节点重新执行。该过程对用户透明，仅表现为该作业在某段时间内的执行速度降低。

#### 3.4.3 Task故障

当TaskTracker检测到一个任务故障，它将在下一次心跳中向JobTracker报告该故障，JobTracker收到消息报告后重新调度执行该任务，该任务可能在集群的任意一个节点重试。若某个任务经过最大尝试数的尝试运行后仍然失败，整个作业被标记为失败。

如果重试Map任务，可以从输入路径（如HDFS）重新读入数据。对于重试的Reduce任务，要重新拉取Map端的输出文件，如果无法读取该文件，则相应的Map任务也需要重新执行。这是因为Map端是将输出结果写入磁盘中的，并且在写入磁盘后才可以被Reduce任务读取，因此只要磁盘数据不丢失，重试的Reduce任务即可读取相应数据。Map任务将输出全部预先写入磁盘后Reduce任务才可读取的设计虽然会造成很高的延迟，但保障了Reduce任务的容错。



## 第 4 章  批处理系统 Spark

最初是基于内存计算的大数据批处理系统，支持大规模数据分析处理。起初在2009年由UC Berkeley的AMP实验室开发。

Spark从最初仅使用内存的批处理系统，转变为了内外存同时使用的批处理系统。

**所以，说Spark是基于内存的，已经不再准确。**

### 4.1 设计思想

#### 4.1.1 MapReduce 的局限性

1. **编程框架的表达能力有限，用户编程复杂。**MapReduce只提供了map和reduce两个编程算子（回忆：MapReduce的逻辑计算模型），用户需要基于二者实现数据处理的操作。一些常用操作需要利用map和reduce才能实现，增加了编程的复杂度。**即，MapReduce比MPI易懂，但还不够。**
2. **单个作业中需要进行Shuffle的数据以阻塞方式传输，磁盘I/O开销大、延迟高。**在单个作业中，需要进行Shuffle的数据首先由Map任务将计算结果写入本地磁盘，之后Reduce任务才可读取该计算结果。因此，需要进行Shuffle的数据磁盘I/O开销大，同时这种阻塞式数据传输方式加剧了MapReduce作业的高延迟。
3. **多个作业之间的衔接涉及I/O开销，应用程序的延迟高。**对于单个MapReduce作业，这是从HDFS获得输入再往HDFS输出的过程。然而，很多应用程序需要通过多个作业完成，例如机器学习的迭代训练过程。因此，在迭代计算过程中，前一个作业需要将迭代计算的结果写入HDFS或其他存储系统，后一个作业从HDFS或其他存储系统中读取该结果并进行新一轮迭代计算。迭代计算中间结果的反复读些导致整个应用的延迟非常高。
4. **（未出现在课本上）**第一代MapReduce资源与作业管理未被分离，耦合度较高。

因此，对MapReduce的改进可以从提高编程框架的表达能力，减少不必要的Shuffle阶段，消除多个衔接的作业之间的I/O 3个方面入手。

#### 4.1.2 数据模型

Spark将数据抽象为弹性分布式数据集（Resilient Distributed Dataset, RDD），其中包含一组数据记录。RDD名称中的3个英文单词分别体现以下3个特性。

1. RDD是一个数据集：与MapReduce不同，Spark的操作对象为抽象的数据集而非文件。
2. RDD是分布式的：每个RDD可划分成多个分区，每个分区即为一个数据集片段，一个RDD的不同分区可以存储于集群中的不同节点。
3. RDD具有弹性：即具备可恢复的容错特性。

#### 4.1.3 计算模型

MapReduce只提供map和reduce两种操作算子，而Spark提供丰富的操作算子以对RDD进行变换。这些操作算子可以分为创建、转换和行动操作算子。

创建：从本地内存或外部数据源创建RDD，提供数据输入的功能。**常见的如hadoopFile。**

转换：描述RDD的转换逻辑，提供对RDD进行变换的功能。**常见的map，flatMap，union，groupByKey，join**。

行动：标志转换结束，触发DAG生成。**常见的reduce，collect，count，countByKey，saveAsTextFile。**

![image-20240615185431995](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240615185431995.png)

![image-20240615185620110](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240615185620110.png)

**注意：这只是一个例子！不意味着所有的Spark的逻辑计算模型都是这样的。只要DAG服从有创建，转换，行动三个操作算子，就可以是Spark逻辑计算模型。**

图4.2从算子操作角度描述计算过程，其中每一个圆形代表一个算子。如果从RDD变换角度描述计算过程，则将得到如图4.3所示的RDD世系（Lineage），图中的每一个矩形代表一个RDD，二者本质上均描述Spark的逻辑计算模型，只是Operator DAG描述的主体为算子而RDD Lineage描述的主体为数据。在RDD Lineage中，通过读入外部数据源进行RDD创建，经过一系列的转换操作，每次均会产生不同的RDD，以供下一个转换操作使用，最后一个RDD经过“行动”操作进行转换，并输出到外部数据源。

注意，RDD的变换过程中，RDD是只读的，不可变（immutable）的。也就是说，RDD转换或行动操作会不断生成新的RDD，而非改变原有的RDD。这遵循了函数式编程的特性，函数式编程中的变量值是不可变的，对于值的操作并非修改原有值，而是产生新的值，同时原有值保持不变。**如果可变，并行会存在问题，容错能力也会失去。**

![image-20240615195826395](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240615195826395.png)

![image-20240615195840142](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240615195840142.png)

物理设计层面，利用分布式架构加快数据处理，因而DAG中的操作算子实际上由若干实例任务（Task）实现。

图4.4从DAG的角度描述物理计算模型，其中一个算子由多个任务实现，事实上每个任务通常负责处理RDD的一个分区。图4.5从RDD的角度描述物理计算模型。

**注意，图4.4中出现的算子数目并不就是实际上需要的Task数量，有的操作算子可以由同一个Task任务实现。后续讨论。**

### 4.2 体系架构

#### 4.2.1 架构图

![image-20240615200329209](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240615200329209.png)

主要包括集群管理器、执行器、驱动器等。

1. 集群管理器（cluster manager）：负责管理整个系统的资源并监控工作节点（worker node），根据系统部署方式的不同，Spark可分为Standalone和Yarn两种模式。其中，Standalone模式不使用Yarn或Mesos等其他资源管理系统，该模式种的集群管理器包含Master和Worker。Yarn模式将Spark与资源管理系统Yarn共同部署，该模式中的集群管理器包含ResourceManager和NodeManager。**Yarn的话题见下一章，这里请先着重理解Standalone。**
2. 执行器（executor）：负责任务执行。执行器本身为运行在工作节点上的一个进程，通过启动若干**线程**执行任务。在Standalone部署方式下，执行器进程的名称为CoarseGrainedExecutorBackend。

**注意，MapReduce的Task是进程，Spark的Task是线程。使用线程，则线程间切换更快；但是要注意线程资源存在制约与干扰，因此使用线程需要硬件较好，而进程则有较好的资源管理。**

3. 驱动器（driver）：负责启动应用程序的主方法并管理作业运行。驱动器在逻辑上独立于主节点，从节点以及客户端，但会根据应用程序的不同运行方式以不同的形式存在。

可以说，**集群管理器负责集群资源管理，而驱动器负责作业管理。**因此，Spark架构实现了资源管理和作业管理两大功能的分离。

![image-20240615202101848](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240615202101848.png)

注意到图4.7上出现了客户端，且客户端上存在名为SparkSubmit的进程。

但是，尚未标出驱动器的位置。这是因为驱动器的位置与客户端选择何种方式执行应用程序有关。

具体来说，客户端可以选择Client或Cluster方式提交应用程序。因此，根据客户端选择的应用程序提交方式，Standalone模式又可以进一步分为Standalone Client模式和Standalone Cluster模式。

Standalone Client模式是指以Standalone方式部署Spark系统，客户端选择以Client方式提交应用程序。

![image-20240615202112741](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240615202112741.png)

此时的驱动器位于客户端，并处于SparkSubmit进程中。此时，客户端可以查看应用程序执行过程中的信息。

Standalone Cluster模式是指以Standalone方式部署Spark系统，客户端选择以Cluster方式提交应用程序。

![image-20240615202121683](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240615202121683.png)

在此模式下，Master将选择在某一Workder所在节点启动名为DriverWrapper的进程作为驱动器。此时，客户端无法查看应用程序执行过程中的信息。

![image-20240615204600479](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240615204600479.png)

#### 4.2.2 应用程序执行流程

![image-20240615204646224](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240615204646224.png)

1. 启动驱动器。以Standalone模式为例，如果使用Client部署方式，则客户端直接启动驱动器，并向Master注册。如果使用Cluster部署方式，则客户端将应用程序提交给Master，由Master选择一个工作节点启动驱动器进程（DriverWrapper）。
2. 构建基本运行环境，即由驱动器创建SparkContext，向集群管理器进行资源申请，并由驱动器进行任务分配和监控。
3. 集群管理器通知工作节点启动执行器进程，该进程内部以多线程方式运行任务。
4. 执行器进程向驱动器注册。
5. SparkContext构建DAG并进行任务划分，从而将其交给执行器进程中的线程以执行任务。

### 4.3 工作原理

驱动器很重要，它创建的**SparkContext维护了应用程序的基本运行信息**。

SparkContext根据RDD的依赖关系构建DAG，由DAG调度器划分DAG Stage，将一个Stage作为一个TaskSet（一组任务的集合）提交给任务调度器，由其将任务分发给各个工作节点上的执行器执行，整个过程按照Stage依次执行。

![image-20240616141408956](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240616141408956.png)

#### 4.3.1 Stage划分

![image-20240616144125925](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240616144125925.png)

RDD之间存在依赖关系，这种依赖关系通常分为窄依赖和宽依赖。

窄依赖表现为：一个父RDD的分区对应于一个子RDD的分区或多个父RDD的分区对应于一个子RDD的分区。如图4.12（a），可能的算子如map，filter，union。

宽依赖表现为：存在一个父RDD的一个分区对应一个子RDD的多个分区。如图4.12（b），可能的算子如groupByKey，join。

DAG调度器通过分析各个RDD中分区之间的依赖关系决定如何划分Stage。简单来说，DAG调度器针对DAG进行反向解析，遇到宽依赖则生成新的Stage，遇到窄依赖则将该Operator加入当前Stage，从而使窄依赖尽可能划分在同一个Stage中。因此，Stage内部生成的RDD之间为窄依赖关系，而Stage输出RDD和下一个Stage输入RDD之间为宽依赖关系。只有Stage之间的数据传输需要进行Shuffle。

![image-20240616145209314](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240616145209314.png)

根据输出的不同，Spark中的Stage分为ShuffleMapStage和ResultStage两种类型。其中，ShuffleMapStage的输出作为另一个Stage（ShuffleMapStage / ResultStage都可）的输入，而ResultStage的输出直接产生最终的结果。对于Stage的输入来说，ShuffleMapStage和ResultStage均可从外部数据源或者另一个ShuffleMapStage的输出获取数据。

ShuffleMapStage的特点是：并非最终的Stage，其后还存在其他Stage；输出必须经过Shuffle过程，作为后续Stage的输入；一个DAG中可能包含该类型Stage，也可能不包含该类型Stage。

ResultStage的特点是：是最终的Stage，且其输出即为最终的结果；一个DAG中必定包含该类型Stage。

因此一个DAG包含一个或多个Stage，其中至少存在一个ResultStage。

#### 4.3.2 Stage内部的数据传输

Spark系统采用流水线（pipeline）方式进行Stage内部的数据传输。与MapReduce中的Shuffle方式不同，流水线方式不要求物化前序算子的所有计算结果。**（“物化”指的是，一个算子的操作会在内存进行，但是生成的新数据会被写到磁盘上。这里的“不要求物化”的意思是指计算结果不会写到磁盘上。）**在Stage内部无需采用Shuffle方式进行数据传输。

![image-20240616151629327](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240616151629327.png)

通常，Spark根据每个Stage**输出的RDD中的分区个数**决定启动的任务数量（TaskSet的大小）。如果该Stage类型为ShuffleMapStage，这些任务是ShuffleMapTask；如果Stage类型是ResultStage，任务是ResultTask。

#### 4.3.3 Stage之间的数据传输

需要Shuffle，这与MapReduce的Shuffle类似。Shuffle过程可能发生在两个ShuffleMapStage之间，或者ShuffleMapStage与ResultStage之间。从Task层面看，该过程表现为两组ShuffleMapTask之间，或一组ShuffleMapTask与一组ResultTask之间的数据传输。

![image-20240616152404595](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240616152404595.png)

为了便于描述，将Shuffle过程分为Shuffle Write和Shuffle Read两个阶段。Shuffle Write阶段，ShuffleMapTask需要将输出RDD的记录按照分区函数划分到相应的bucket中并物化到本地磁盘形成ShuffleblockFile，之后才可以在Shuffle Read阶段被拉取。在Shuffle Read阶段，ShuffleMapTask或ResultTask根据Partition函数读取相应的ShuffleblockFile，将其存入缓冲区并继续进行后续的计算。**图中的Buffer都是内存里的缓冲区。**

注意，Buffer并不一定要求对该Task负责处理的所有记录进行排序后才进行后续处理，这与MapReduce中Reduce Task端先对所有记录先排序再执行reduce方法存在差异。

#### 4.3.4 应用与作业

![image-20240616153405557](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240616153405557.png)

更确切的说，Spark应用的范围是从Spark Context的创建到关闭。从逻辑执行角度看，一个Application由一个或多个DAG构成，一个DAG由一个或多个Stage构成，一个Stage由若干RDD Operator（若干窄依赖的RDD操作）构成。从物理执行角度来看，一个Application等于一个或多个Job，一个Job由一个或多个TaskSet构成，一个TaskSet为多个不存在Shuffle关系的Task集合。

**（PowerPoint）**

Application：用户编写的Spark应用程序。

Job：一个Job包含多个RDD及作用于相应RDD的转换操作，最后一个为action。

MapReduce中，一个应用就是一个作业。

Spark中的一个应用可以由多个作业来构成。

**从具体代码角度再次解释：**

写在代码里的算子是不会立即计算的，而是依次记录下来形成一个DAG。只有当一个行动操作被调用时，Spark才会根据逻辑执行计划（DAG）生成物理执行计划，触发实际计算。而每次行动操作，会启动一个新的Job。

### 4.4 容错机制

在应用程序运行过程中系统发生故障的类型可以分为Client故障，Master故障，Worker故障，Executor故障。

对Client故障来说，需要分为Standalone Client模式和Standalone Cluster模式两种情况讨论。在Standalone Client模式中，驱动器存在于该进程将导致系统无法正常工作，用户需要重新提交应用程序；在Standalone Cluster模式中，只要作业成功提交给系统，Client故障便不会影响系统中的作业运行。

值得指出的是，Standalone Cluster模式中的Driver进程故障将导致系统无法正常工作，用户需要重新提交应用程序。

对于Master故障来说，发生该故障后系统无法正常工作，需要重新启动，或借助ZooKeeper（配置多个Master）实现高可用性。

对于Worker或Executor故障来说，该类故障仅影响系统中局部计算的结果，系统可以重启发生故障的进程或将其丢弃并将原本由这些进程负责执行的任务交给新的Worker或Executor执行。

从RDD计算的角度来看，Worker或Executor故障将导致部分RDD或RDD中的某些分区丢失。因此，本节主要讨论如何恢复丢失的RDD或RDD分区。

#### 4.4.1 RDD持久化

Worker进程可以管理一定大小的内存，主要用于存储RDD和计算过程中需要的其他辅助信息等。由于计算过程会不断地产生新的RDD，因此系统无法将所有的RDD均存储于内存中。一旦达到相应存储空间的阈值，Spark会使用置换算法（如LRU，Least Recently Used，最近最少使用）将部分RDD的内存空间腾出。如果不做任何声明，这些RDD将被直接丢弃。但是，某些RDD后续很可能被再次使用，例如迭代计算过程中每轮计算均参与的RDD。那么，用户在编程时可以标明该类RDD需要持久化，使用persist(Storagelevel)方法或cache()方法实现持久化（写入内存的缓冲区，或写入磁盘）。

用户可以通过缓存RDD加快计算速度，并利用多个备份快速恢复因故障丢失的数据分区。因此，用户进行显式持久化的功能是多方面的。此外，系统在RDD计算过程中也会进行自动（隐式）持久化，即自动保存部分Shuffle过程的数据。

#### 4.4.2 故障恢复

驱动器中的SparkContext维护了记录RDD转换操作的DAG，即RDD的血缘关系（Lineage）。相比于数据库系统细粒度的日志机制，RDD Lineage记录的是粗粒度的变换操作。当某一RDD的部分分区丢失时，其可通过Lineage获取足够的信息以重新运算和恢复丢失的数据分区。因此，结合计算过程中某些持久化的RDD和Lineage信息即可进行故障恢复。

根据RDD的不同依赖关系，窄依赖可以在某个计算节点上直接通过计算父RDD中某个分区的数据得到子RDD对应的分区数据；宽依赖则需等待父RDD的所有数据计算完成，并且父RDD的计算结果经过Shuffle并传至对应节点后才能计算子RDD。重算过程在不同节点之间可以并行。

![image-20240616195903458](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240616195903458.png)

#### 4.4.3 检查点

虽然RDD的持久化机制可以提供一定程度的多备份，但是多个备份的物理机器可能同时发生故障，从而导致该RDD丢失。极端情况下，系统只维护了当前产生的RDD并且Lineage较长，此时故障将导致系统的恢复过程根据RDD Lineage重新开始计算。此外，如果RDD Lineage中存在大量宽依赖，则恢复过程的代价较高。因此，在Lineage较长尤其存在宽依赖时，需要在适当的时机设置数据检查点。

检查点机制将RDD写入可靠的外部分布式文件系统，例如HDFS。如果用户指定某些RDD需要设置检查点，则系统将在作业结束之后启动一个独立的作业进行写检查点操作。与RDD持久化中在Spark内部的某些节点存储多个备份不同，检查点的内容存储于外部的HDFS等系统中，这些系统本身具备容错能力。也就是说，检查点用于辅助基于RDD Lineage的故障恢复。当Lineage过长或宽依赖过多时，如果对中间某个RDD进行写检查点操作，则之后发生节点故障时，从生成检查点的RDD开始按照Lineage重新执行计算，能够加快恢复过程。



## 第 5 章 资源管理系统 Yarn

Yarn最初是为MapReduce设计的一种资源管理器，后逐步成为一个通用的资源管理系统，可为上层应用提供统一的资源管理和调度。Yarn系统的引入为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处。

2010年，雅虎的工程师开始考虑MapReduce的新架构。

2012年8月，Yarn成为Apache Hadoop的一个子项目。因此可以认为，第 3 章介绍的是第一代MapReduce，本章介绍的是引入Yarn之后产生的第二代MapReduce。

### 5.1 设计思想

第一代MapReduce存在一定局限性，其中一个显著的缺陷是资源管理和作业紧密耦合。Yarn的出现使得资源管理模块从第一代MapReduce中独立，成为一个通用的资源管理平台，而MapReduce、Spark以及后续将要介绍的其它系统则作为运行于该平台之上的框架。

#### 5.1.1 作业与资源管理

第一代MapReduce系统中，JobTracker控制TaskTracker并管理集群资源的分配与释放，以及作业生命周期，包括调度作业的每个任务，追踪任务进度等。因此，JobTracker主要完成资源管理和作业管理两大功能。而TaskTracker的功能十分简单——依次启动和停止由JobTracker分配的任务，并且周期地向JobTracker汇报任务进度和状态信息。

4.1.1 从编程框架和作业执行等角度阐述了第一代MapReduce的局限性。从系统架构的角度来看，第一代MapReduce的体系架构存在如下缺点。

1. **资源管理与作业紧密耦合。**在该架构中，JobTracker既负责作业管理和任务调度，又负责管理集群中的资源。因此，资源管理与MapReduce作业之间存在紧密的耦合。然而，并非只有MapReduce作业需要进行资源管理，Spark作业以及下文要介绍的Flink作业等均需进行资源管理。也就是说，资源管理与具体的作业无关。
2. **作业的控制管理高度集中。**该架构中的JobTracker负责系统中所有作业的控制，JobTracker需要维护所有作业的元信息，内存开销较大。当同一时刻执行的作业数量增加时，JobTracker与执行这些作业的任务以及TaskTracker之间的通信频率增大，造成JobTracker进程的不稳定。

基于上述局限性，Yarn将资源管理功能从第一代MapReduce系统中独立，通过将资源管理与作业分离形成通用的资源管理系统，并使作业之间相互独立地控制执行。

**其实Spark实现了资源管理和作业的分离。**

#### 5.1.2 平台与框架

从Yarn作为资源管理系统的角度来看，其不仅可以运行MapReduce作业，而且可以运行Spark应用等。如果将资源管理系统视为一个提供资源的平台（Platform），则可在该平台上运行MapReduce、Spark、Flink等系统。与平台相对应，将运行在资源管理平台上的分布式计算系统称为框架（Framework）。也就是说，平台提供资源管理的功能，而框架为运行在平台上的系统。

**平台（Platform）：具有提供资源功能的系统**

**框架（Framework）：运行在平台上的系统**

Yarn进行资源管理的粒度是应用，称其为Yarn平台的应用。需要注意的是，**Yarn平台的应用**和**框架的应用**并不一定一致，框架可以将其应用或作业映射为Yarn平台的应用。例如，MapReduce将一个作业对应为一个Yarn的应用，而Spark将一个应用对应为一个Yarn的应用。此外，需要注意框架中的应用（Application）和作业（Job）两个概念。比如，Spark中的一个应用是一个或多个Job。

### 5.2 体系架构

#### 5.2.1 架构图

![image-20240617203854811](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240617203854811.png)

Yarn采用主从架构，包括主节点运行的ResourceManager、从节点运行的NodeManager和提交应用程序的客户端（Client）。其中，ResourceManager和NodeManager是Yarn的常驻进程，而从节点中的ApplicationMaster是用于某一应用管理的进程，Container表示可以用于执行该应用中具体任务的资源。

1. ResourceManager（RM）：负责整个系统的资源管理和分配的资源管理器，主要由调度器和应用管理器两个组件构成。其中，调度器负责分配Container并进行资源调度，应用管理器负责管理整个系统中运行的所有应用，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster的运行状态等。
1. NodeManager（NM）：负责每个节点资源和任务管理的节点管理器。一方面，NM定时向RM汇报本节点的资源使用情况和Container运行状态；另一方面，NM接受并处理来自AM的Container启动/停止等各种请求。
1. ApplicationMaster（AM）：每当用户基于Yarn平台提交一个框架应用，Yarn均启动一个AM以管理该应用。一方面，AM与RM调度器通过协商获取资源（以Container表示），将获取的资源进一步分配给作业内部的任务；另一方面，AM与NM通过通信启动/停止任务，监控所有任务运行状态，并在任务发生故障时重新申请资源以重启任务。
1. Container：Container为资源的抽象表示，包含CPU、内存等资源，是一个动态资源划分单位。当AM向RM申请资源时，RM向AM返回以Container表示的资源。

Yarn实现了资源管理与作业管理相分离。MapReduce 1.0既是计算系统，需要负责作业管理，也是资源管理系统。Yarn是独立出来的资源管理系统，而MapReduce 2.0作为计算系统负责作业管理。

![image-20240619151028121](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240619151028121.png)

#### 5.2.2 应用程序执行流程

当用户向Yarn提交应用程序后，Yarn首先启动ApplicationMaster，然后由ApplicationMaster根据应用程序进行任务划分，并为各个任务申请资源，同时监控整个运行过程。

![image-20240619152230454](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240619152230454.png)

1. 用户编写客户端应用程序，向Yarn提交应用程序。
2. RM负责接收和处理来自客户端的请求，尝试为该应用程序分配第一个Container，若分配成功则在该Container中启动应用程序的AM。
3. AM向RM注册，以便客户端通过RM查看应用程序的资源使用情况。AM将应用解析为作业并进一步分解为若干任务，并向RM申请启动这些任务的资源。
4. RM向提出申请的AM分配以Container形式表示的资源。一旦AM申请到资源，即可在多个任务间进行资源分配。
5. AM确定资源分配方案后，与对应的NM通信，在相应的Container中启动相应的工作进程以执行任务。
6. 各个工作进程向AM汇报自身的状态和进度，以便令AM随时掌握各个工作进程的任务运行状态。
7. 随着任务执行结束，AM逐步释放占用的资源，最终向RM注销并自行关闭。

注意，上述步骤描述的是MapReduce，Spark等批处理应用程序的执行流程，这些应用程序在一定时间内可完成运行并正常退出我。而后续章节将介绍的流计算应用程序除非发生故障或手动关闭，否则将持续运行。但两类应用程序在Yarn上的启用流程是相同的。

### 5.3 工作原理

Yarn作为资源管理的平台，可以运行多个框架，并为多个应用（包括相同框架的多个应用，以及不同框架的多个应用）进行资源的分配。

#### 5.3.1 单平台多框架

在不使用资源管理系统的情况下，如果将MapReduce，Spark等系统部署在同一个物理集群中，则其将静态地划分所占用的物理资源，无法实现动态地共享。

Yarn作为资源管理的统一平台，在该平台中可以运行MapReduce，Spark，Flink等多种框架的应用。对于Yarn来说，该平台只负责向框架提供Container，并不关心在Container中运行何种任务。通过Yarn资源管理平台，多个框架可以部署在同一个物理集群中并动态地共享资源。

![image-20240620005802322](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240620005802322.png)

如图，Yarn平台中部署了MapReduce和Spark两个计算框架，并且提交了2哥MapReduce应用和1个Spark应用。由此看出，每当提交一个应用，Yarn均会启动一个对应的ApplicationMaster。即使均为同一类型的应用，也会启动不同的AM，达到了应用之间相互独立地控制执行的目的。

#### 5.3.2 平台资源分配

Yarn平台既可以运行相同框架的多个应用，又可以运行不同框架的多个应用。因此，如何对应用进行资源分配是Yarn作为资源管理平台要解决的核心问题。在Yarn平台中，RM的调度器维护了一个或多个应用队列（queue），每个队列拥有一定数量的资源，位于同一队列的应用共享该队列所拥有的资源。Yarn平台进行资源分配的对象是应用，用户提交的每个应用会分配到其中一个队列中，而队列决定了该应用能够使用的资源上限。资源调度实际上是决定如何将资源分配给队列，以及分配给队列中应用的过程。值得注意的是，上一小节指出AM向RM发出资源请求从而分配Container执行任务，该过程由框架决定。也就是说，Yarn平台为应用分配一定的资源，而框架决定如何使用这些资源执行任务。Yarn中的调度器是一个可插拔的组件，可以通过配置文件选择不同的调度器。

三种常见调度器：**FIFO, Capacity, Fair**

![image-20240620011522728](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240620011522728.png)

FIFO调度器：仅维护一个队列，该队列拥有集群中的所有资源，调度器的资源分配方式为先提交的应用先得到资源（先到先得）。它的实现简单，但问题是可能导致一个应用独占所有资源而其他应用需要不断等待，**平均每个应用等待时间过长。**

![image-20240620011531477](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240620011531477.png)

Capacity调度器：改进FIFO调度器的思想是将一个队列分解为多个队列，每个队列均拥有一定数量的资源。因此，某一应用最多仅占用其中一个队列拥有的资源，不会占用集群中的所有资源。Capacity调度器维护了层级式的队列，集群中的资源划分给这些队列，队列内部的资源分配方式为FIFO，用户提交应用程序时可以指定将该应用放入某一队列。这可以避免某个长时间运行的应用独占集群资源而其他应用得不到运行的情况。问题是在图中，在提交应用2之前，队列B中的资源处于空闲状态，因而造成了集群资源的浪费。

![image-20240620011658936](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240620011658936.png)

Fair调度器：改进Capacity调度器的思想是允许队列间共享资源，从而避免浪费。基于上述思想，Fair调度器可以维护层级式的队列，集群中的资源划分给这些队列，但是队列之间可以共享资源，因而这些队列在逻辑上可以看作一个共享队列。当只有一个应用运行时，该应用可以独占整个集群资源。但当其他应用提交到集群时，将空出部分资源给新的应用，最终所有的应用会根据所需使用内存的大小得到分配的资源。**它并不是完美的，图中的虚线和应用2之间实际上存在一个空隙，这是因为会发生抢占。必须要确保应用1某一部分的资源的运算结束后，才可以分配给应用2，否则会出现问题。**

### 5.4 容错机制

系统发生故障的类型可以分为主节点故障和从节点故障。其中，主节点故障表示RM进程故障，从节点故障表示NM进程故障。当然，从节点故障同样可能导致AM以及Container中运行的任务发生故障。由于AM以及Container中运行的任务与具体框架有关，因此作为资源管理平台的Yarn在该类任务发生故障时只会帮助其重新启动，而运行过程需要由框架完成恢复。**因此，AM故障和Container中的任务故障时，容错方式是重启，而且Yarn实际上作为资源管理系统也不为此负责。**

如果RM发生故障，则在进行故障恢复时需要从某一持久化存储系统中恢复信息。恢复完毕后，RM会清除当前所有集群中的所有Container，包括运行AM的Container。然后，RM重新启动AM，也即表示所有应用将重新执行。当然，可以部署多个RM并通过ZooKeeper进行协调，从而保证RM的高可用性。**（持久化存储系统，指的是可以持久性存储数据的平台，比如从内存中存储到HDFS中）**

由于NM和RM一直保持心跳通信，因此RM通过超时机制可以判断某个NM是否发生故障。如果NM发生故障，则RM认为NM所在节点中的所有容器运行的任务均执行失败，并将执行失败的信息告知AM。因此，AM将向RM重新申请资源运行这些任务。显然，RM将分配其他节点的Container以执行这些任务。如果发生故障的NM完成恢复，则向RM重新注册，重置本地的状态信息。

### 5.5 典型示例

#### 5.5.1 Yarn平台运行MapReduce框架

![image-20240620020204093](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240620020204093.png)

![image-20240620020331207](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240620020331207.png)

注意进程名称：MRAppMaster，YarnChild

自从Hadoop项目引入Yarn，MapReduce必须通过Yarn才可以运行，不再像第一代MapReduce那样可以独立运行。

#### 5.5.2 Yarn平台运行Spark框架

在不使用Yarn的情况下，Spark系统可以独立部署，即Standalone模式。并且根据Driver运行位置的不同，该模式可进一步分为Standalone Cluster和Standalone Client两种模式。在Yarn模式，类似地，根据Driver运行位置的不同，该模式可进一步分为Yarn Cluster和Yarn Client两种模式。

![image-20240620021026354](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240620021026354.png)

Yarn Cluster模式是指基于Yarn平台部署Spark，并且客户端选择以Cluster方式运行应用程序。每当客户端向RM提交一个Spark应用，RM即随机选取一个NM所在节点启动名为AM的进程，Driver运行于该进程中并且由该进程负责管理该Spark应用，AM根据Yarn分配的资源进行任务调度，并启动CoarseGrainedExecutorBackend进程执行任务。Yarn Cluster模式与Standalone Cluster模式非常相似，只是具体进程的名称有所不同。

![image-20240620022456564](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240620022456564.png)

Yarn Client模式是指基于Yarn平台部署Spark，并且客户端选择以Client方式运行应用程序。每当客户端向RM提交一个Spark应用，RM即随机选取一个NM所在节点启动名为ExecutorLauncher的进程。但是与Yarn Cluster模式中的AM相比，ExecutorLauncher仅负责向RM申请资源启动CoarseGrainedExecutorBackend进程，并不负责运行Driver。与Standalone Client模式类似，Yarn Client模式中的Driver仍然运行在客户端的SparkSubmit进程中。值得注意的是，Yarn Client模式下的ExecutorLauncher进程既不管理资源也不管理应用，仅负责资源的申请和释放。Yarn Client模式主要用于代码调试，在生产环境下应当使用Yarn Cluster模式。

**GPT-4o谈治Spark理政：之所以在调试的时候用Client模式，是因为这时候客户端是可以看到Spark的运行状态的。但之所以生产环境下用Cluster，是因为：驱动程序在Yarn管理的节点上，节点故障更好应对，且客户端故障也不影响Spark运行；减少了跨网络通信的延迟，提高了整体性能。**

#### 5.5.3 Yarn平台运行MapReduce和Spark框架

![image-20240620210555237](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240620210555237.png)

Spark应用程序以Yarn Cluser模式执行。

当MapReduce客户端向RM提交应用后，Yarn将启动MRAppMaster进程管理该应用，MRAppMaster根据Yarn分配的资源进行任务调度，并启动YarnChild进程执行Map或Reduce任务。当Spark客户端向RM提交应用后，RM随机选取一个NM所在节点启动名为AM的进程，Driver运行于该进程中并且由该进程负责管理该Spark应用，AM根据Yarn分配的资源进行任务调度，并启动CoarseGrainedExecutorBackend进程执行任务。



## 第 10 章 批流融合系统 Flink

Flink起源于Stratosphere项目，于2008年设立。项目负责人为柏林工业大学（TU Berlin）的Volker Markl教授。徐辰也参与研发。

Stratosphere最初是一个批处理系统，其扩充MapReduce的算子，引入流水线方式进行数据传输。该设计为Flink系统支持流计算奠定了基础。

### 10.1 设计思想

作为一个同时支持批处理和流计算的批流融合系统，按照Dataflow模型的观点，Flink需要同时处理有界数据和无界数据。Flink系统的设计思想是以流计算为中心，将有界数据视为无界数据的特例。因此，Flink系统将需要处理的数据抽象为DataStream形式，并使用DAG描述计算过程。此外，与Spark等系统不同，Flink同时提供内置的迭代算子以原生地支持迭代计算。

#### 10.1.1 数据模型

![image-20240621191801531](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240621191801531.png)

Flink将输入数据看作一个不间断的、无界的记录序列，一系列记录构成DataStream。Flink程序使用DataStream类表示无界数据，其为一个可以包含重复项的不可变数据集合。首先，DataStream中的记录可以是无界的。其次，与Spark RDD类似，DataStream中的记录是不可变的，一旦创建即无法在物理上改变。

Flink程序目前可以使用DataSet类表示有界数据。与DataStream不同，DataSet中的数据是有界的。但与DataStream相同的是，DataSet中的记录同样不可变。值得指出的是，由于有界数据为无界数据的一种特例，因此DataSet从理论上说可以完全由DataStream替代，也就是说DataStream同样可以表示有界数据。但是由于Flink发展演变的历史原因，DataSet出现后才有了DataStream，本章讨论Flink时重点围绕DataStream展开。

![image-20240621192501320](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240621192501320.png)

MapReduce模型以键值对作为数据模型，Spark系统以RDD作为数据模型，Flink系统以DataStream作为数据模型。MapReduce将数据抽象到记录级别，Spark系统与Flink系统将数据抽象到记录集合级别。MapReduce和Spark系统的数据模型认为输入数据是有界的，Flink系统的数据模型认为输入数据是无界的。**可以理解为，MapReduce与Spark是静态的，Flink是动态的。**

#### 10.1.2 计算模型

Flink系统中提供丰富的操作算子以对DataStream进行转换，DataStream经转换操作得到新的DataStream，该过程与Spark中RDD经转换操作生成新的RDD十分类似。一系列转换操作构成一张有向无环图，即描述计算过程的DAG。

操作算子可分为：

1. 数据源（DataSource）：描述DataStream数据的来源。
2. 转换（Transformation）：描述DataStream在系统中的转换逻辑。
3. 数据池（DataSink）：描述DataStream数据的走向。

Flink中，DataSink标志计算DAG的结束，而Spark中的Action操作标志计算DAG的结束。

![image-20240621193312492](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240621193312492.png)

在物理设计层面，Flink利用分布式架构加快数据处理，因而DAG中的操作算子实际上由若干实例任务（task）实现。图10.2中，socketTextStream和print算子的并行度为1，即由1个任务实现，其余算子的并行度为2，即由2个任务实现。数据传递的方式（即需不需要算子之间的交换）由语义（算子）决定。

通常来说，Flink系统中的一个应用对应一个DAG，而Spark中的一个应用包含一个或多个DAG。

#### 10.1.3 迭代模型

MapReduce实现迭代计算的方式是将一轮迭代计算作为一个作业提交给MapReduce系统。在Spark中，用户编写带有循环的应用程序，由驱动器控制迭代计算的执行。两种方式的共同特点是，迭代计算的过程由用户编写的外部驱动程序控制。与此不同，Flink系统将迭代作为内部算子嵌入DAG中实现迭代计算，即由系统控制迭代计算过程。

![image-20240621195008179](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240621195008179.png)

这听起来似乎有些矛盾——DAG是一个有向无环图，而迭代计算必然存在环路。事实上，迭代计算作为一个算子嵌套在DAG中，对于DAG来说整个迭代过程为一个算子，该迭代算子的内部实现存在反馈的环路。

由于迭代计算的特殊性，批式迭代计算和流式迭代计算在语义上有所差异。在批式迭代计算中，输入数据是有界的，每轮迭代计算的全部结果一般均作为下一轮迭代计算的输入，并且迭代过程将在满足收敛条件时停止。在流式迭代计算中，输入数据是无界的，通常每轮迭代计算的部分结果作为输出向后传递，而另一部分结果作为下一轮迭代计算的输入，并且迭代过程是无限的。

在迭代计算中，由于有界数据和无界数据语义上的差别，针对二者的迭代计算需要使用不同的算子。Flink中的批式迭代计算需要使用DataSet接口，流式迭代计算需要使用DataStream接口。

![image-20240621200533290](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240621200533290.png)

### 10.2 体系架构

#### 10.2.1 架构图

![image-20240621195553827](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240621195553827.png)

与Spark类似，根据是否使用Yarn资源管理系统进行系统部署，Flink的具体架构可以分为Standalone和Yarn两种模式。与Spark不同的是，Flink目前并没有使用驱动器进行作业管理，而是由JobManager负责，因此不存在Client和Cluster模式之分。Flink同样采用主从架构，JobManager是主节点，TaskManager是从节点。

1. Client：客户端，将用户编写的DataStream程序翻译为逻辑执行图并进行优化，并将优化后的逻辑执行图提交到JobManager，系统运行时Client的进程名为CliFrontend。
2. JobManager：作业管理器，根据逻辑执行图生成物理执行图，负责协调系统的作业执行，包括任务调度、协调检查点和故障恢复等。此外，在Standalone模式下，JobManager同样负责Flink系统的资源管理，系统运行时的进程名为StandaloneSessionClusterEntrypoint。
3. TaskManager：任务管理器，用于执行JobManager分配的任务，并且负责读取数据、缓存数据以及与其他TaskManager进行数据传输。此外在Standalone模式下，TaskManager同样负责所在节点的资源管理，将内存等资源抽象为若干TaskSlot并用于任务执行，系统运行时的进程名为TaskManagerRunner。

![image-20240622005135310](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622005135310.png)

从基础接口的角度来看，MapReduce提供的基本编程接口近似于命令式**（命令机器如何做，无论我想要什么，它都只是听我的命令）**，Spark和Flink的编程接口更加丰富，更加趋向于声明式编程风格**（告诉机器我想要什么，机器会想具体怎么做）**。

除Standalone模式外，Flink的Yarn模式基于Yarn进行系统部署。当运行在Yarn平台时，Flink需要将应用或作业映射为Yarn的应用。Flink中既支持将一个作业映射为一个Yarn的应用，又支持将一个应用映射为一个Yarn的应用。前者称为作业（per-job）运行模式，后者称为应用（application）运行模式。

本书仅以作业运行模式为例进行分析。

![image-20240622005948595](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622005948595.png)

资源管理功能由RM和NM两个进程负责，YarnJobClusterEntrypoint进程基于Yarn运行Flink作业的AM，负责管理该作业，并根据Yarn分配的资源进行任务调度，同时启动YarnTaskExecutorRunner进程执行任务。

![image-20240622010751651](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622010751651.png)

#### 10.2.2 应用程序执行流程

在Standalone模式下，除客户端外，Flink系统仅具有JobManager和TaskManager两类部件，即StandaloneSessionClusterEntrypoint和TaskManagerRunner进程。

![image-20240622011225564](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622011225564.png)

1. 客户端将用户编写的程序进行解析，并将解析后的作业描述交给StandaloneSessionClusterEntrypoint。
2. StandaloneSessionClusterEntrypoint根据作业描述进行任务分解，确定各个TaskManagerRunner负责执行的任务。
3. TaskManagerRunner执行各自负责的任务。

在Standalone模式下，当用户使用客户端提交Flink应用程序时，可以选择Attached方式或者Detached方式。其中，Attached提交方式下客户端将与JobManager保持连接，可以获取关于应用程序执行的信息；Detached提交方式下客户端将与JobManager断开连接，无法获取关于应用程序执行的信息。

![image-20240622012419002](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622012419002.png)

**执行过程太长了，见课本。实际上，理解Yarn以后再看会流畅很多。**

类似地，在Yarn模式下，用户同样可以选择Attached方式或者Detached方式提交应用程序。其中，Attached提交方式下CliFrontend将与YarnJobClusterEntrypoint保持连接，可以获取关于应用程序执行的信息；Detached提交方式下CliFrontend将与YarnJobClusterEntrypoint断开连接，无法获取关于应用程序执行的信息。

对于Standalone模式而言，如果同时提交多个不同的Flink作业，则执行作业的任务均在TaskManager中进行分配。因此，同一个TaskManager可能同时执行不同作业的任务，在某种程度上会存在作业之间的相互干扰。例如，某一任务执行失败导致TaskManager崩溃，同时将影响该TaskManager中另一作业的正常运行。根本原因在于作业管理与资源管理并未分离。引入Yarn等资源管理系统后，采用作业运行模式，不同Flink作业的执行互不干扰。类似地，采用应用运行模式，不同Flink应用的执行互不干扰。此外，Flink支持会话（session）运行模式，该模式将所有作业或应用映射为一个Yarn应用。然而，会话运行模式与Yarn中作业之间相互独立的理念矛盾，通常仅用于调试等场合。

### 10.3 工作原理

![image-20240622202934566](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622202934566.png)

在Flink应用程序的执行过程中，Client根据DataStream程序生成逻辑执行图并进行优化，之后将优化后的逻辑执行图提交给JobManager。JobManager获得逻辑执行图后生成物理执行图，从而分配给TaskManager执行。TaskManager启动Task线程执行JobManager分配的任务，在执行过程中任务之间需要进行数据传输。Flink系统内置了迭代算子，因而TaskManager中的任务可以分为实现迭代算子的迭代任务和其他非迭代任务。

#### 10.3.1 逻辑执行图的生成与优化

![image-20240622203240707](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622203240707.png)

给定用户编写的DataStream程序，Flink的Client将其解析生成逻辑执行图（DAG），Client进一步分析各个算子之间的数据依赖关系，借用Spark中描述RDD依赖关系时的宽依赖和窄依赖的概念，如果算子之间的数据依赖为窄依赖关系，则算子之间呈现一对一的数据传递关系。如果算子由处于不同TaskManager的任务实现，则会带来不同TaskManager之间的数据传输。由于算子之间呈现一对一的数据传递关系，因此为了避免算子由处于不同TaskManager的任务实现，Flink使用Chaining机制进行优化，将部分算子合并为一个“大”算子。Chaining优化并不改变算子的语义，但可以避免数据在不同TaskManager之间的非必要传输。

Spark的Pipeline机制使用同一组任务执行位于Stage内部的算子，实际上完成了将Stage内部的算子进行合并的过程。

**由于是动态的数据，不能知道数据的分布，因此无法做更多优化。**

#### 10.3.2 物理执行图的生成与任务分配

![image-20240622205514552](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622205514552.png)

JobManager收到Client提交的逻辑执行图后，根据算子的并行度，将逻辑执行图转换为物理执行图。物理执行图中的一个节点对应一个任务，将分配给TaskManager执行。

![image-20240622205750388](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622205750388.png)

JobManager生成物理执行图后，将各个算子的任务分配给TaskManager。任务分配的基本原则是：根据任务槽（TaskSlot）的容量，尽可能将存在数据传输关系的算子实例放在同一个任务槽中，以保持数据传输的本地性。

可以看出，在Flink中Client将用户编写的程序翻译为逻辑执行图，然后由JobManager进一步转换为物理执行图。在Spark中，客户端向驱动器提交用户编写的程序，驱动器中的解析器根据用户代码生成DAG，再由DAG调度器划分Stage并交给Task调度器。如果将DAG看作逻辑执行图，将一系列Stage看作物理执行图，则可认为Spark中的驱动器完成了从用户程序到逻辑执行图，再到物理执行图的转换过程。这种从用户代码到执行图生成的过程与数据库解析SQL语句产生逻辑执行计划并进行优化，再生成物理执行计划的过程非常相似。

#### 10.3.3 非迭代任务间的数据传输

![image-20240622212035690](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622212035690.png)

如果实现非迭代算子的任务位于不同的TaskManager，则Flink将采用流水线机制进行数据传输。Flink的流水线传递机制是非阻塞式的数据传输方式。Flink的流水线机制一次传输一个缓冲区（buffer），该缓冲区中通常存储不止一条记录。TaskManager设置固定大小的缓冲区，一旦缓冲区满或者达到预先设定的时间阈值，则向负责接收数据的TaskManager发送数据。**看图的话，会觉得数据是被发送给另一个TaskManager的缓冲区。**

![image-20240622213104667](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622213104667.png)

Flink的流水线传输机制决定了DataStream的生成方式与Spark中RDD的生成方式存在显著区别。Spark由于采用阻塞式数据传输方式，根据一个“完整”的RDD计算得到另一个“完整”的RDD，因而RDD的生成也为阻塞式。Flink中的数据发送条件实际上相当于一个“不完整”的DataStream生成另一个“不完整”的DataStream，并且DataStream中的记录不断发生变化，除非缓冲区足够大并且超时的阈值无穷大。相比RDD的生成方式，DataStream的生成为非阻塞式，DataStream中数据的“不完整”和不断变化的特点导致其无法像RDD那样支持DataStream的持久化，Flink系统也无法像Spark那样利用RDD Lineage进行故障恢复。**由于MapReduce和Spark都需要Shuffle，追求上游的任务必须等到所有记录均计算结束后才可向下游任务传递数据，数据先压在磁盘里再传输，Flink却只是放入缓冲区，因此Flink传输更快，但容错是需要修改的。**

![image-20240622213128648](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622213128648.png)

#### 10.3.4 迭代任务间的数据传输

![image-20240622213255959](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622213255959.png)

Flink利用迭代前端（Iteration Source）和迭代末端（Iteration Sink）两类特殊的任务实现数据反馈，两类任务成对处于同一个TaskManager，迭代末端任务的输出可以再次作为迭代前端任务的输入。在流式迭代计算中，通常每轮迭代计算的部分结果作为输出向后传递，而另一部分结果作为下一轮迭代计算的输入，并且迭代过程将持续进行。因此，上述使用迭代前端和迭代末端两个任务协作执行的方式已经能够满足流式迭代计算的需要。由于迭代前端下一轮的计算并不依赖于迭代末端在前一轮迭代得到的所有记录，流式迭代计算中迭代前端收到迭代末端的反馈后即可立即进行新一轮迭代计算，因而数据传输可以按照上一节描述的**流水线**方式进行。

![image-20240622213916264](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622213916264.png)

在批式迭代计算中，每轮迭代计算的全部结果通常均作为下一轮迭代计算的输入，直到迭代过程在满足收敛条件时停止迭代计算。因此，批式迭代计算需要控制每一步迭代计算过程以及整个迭代计算的结束。当满足收敛条件时，迭代前端发送特殊的控制事件，即特殊的记录，表示迭代计算的结束。与流式迭代计算存在显著不同，批式迭代计算中迭代前端下一轮的计算依赖于迭代末端在前一轮迭代得到的所有记录，批式迭代计算中迭代前端必须在收到迭代末端反馈的所有记录后才可开始新一轮迭代计算。因此，迭代前端存在等待迭代末端反馈所有记录的阻塞过程，无法采用上一节描述的流水线机制进行数据传输。

![image-20240622214323974](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240622214323974.png)

目前Flink的流式迭代和批式迭代需要分别通过DataStream和DataSet两种接口实现，因此，Flink执行DataStream程序时采用流水线机制。也就是说，如果不考虑批式迭代任务间的数据传输，则Flink中不同算子任务间的数据传输均采用流水线机制。

### 10.4 容错机制

JobManager故障，TaskManager故障，Client故障。其中，如果仅Client发生故障，则只要作业成功提交给系统即不会影响系统中作业的运行。JobManager负责系统的作业管理和资源管理，一旦发生故障将导致系统无法正常工作，需要重新启动或借助ZooKeeper实现高可用性。然而，TaskManager故障将导致部分计算任务失败，系统可以重启TaskManager或将其丢弃并将本由这些TaskManager负责执行的任务交给新的TaskManager。

Flink无法像RDD那样支持DataStream的持久化，也无法像Spark那样利用RDD Lineage进行故障恢复。为了支持Flink的容错，需要考察计算过程中DataStream的“不完整”记录，这些记录实际上是相应操作算子在计算过程中的状态。

#### 10.4.1 状态管理

在输入数据无界的场景中，数据会源源不断地流入Flink系统。

Flink系统提供特殊的数据结构，即状态（State），用于保存操作算子的计算结果。**由系统提供，避免了个别节点发生故障的情况下数据结构的丢失。**

**注意，算子的状态与进程/节点的状态有区别。**

**状态：系统定义的特殊的数据结构，用于记录需要保存的算子计算结果。**状态可以看作操作算子的记忆能力，可以保留已处理记录的结果，并对后续记录的处理造成影响。具备记忆能力的算子称为有状态算子，例如聚合操作（如window，sum，他们出错难恢复）。与之相反，不具备记忆能力的无状态算子仅考虑当前处理的记录，不会受已处理记录影响，也不会影响后续待处理的记录（如map）。系统实现无状态算子无需使用状态，但是用户程序依然可以在无状态算子的自定义函数中使用状态。

由此可见，保障DAG中某个算子容错的措施是在运行时保存其状态，在发生故障时重置状态，并且继续处理结果尚未保存到状态中的记录。对于整个DAG来说，如果可以在“同一时刻”保存所有算子的状态并形成检查点，一旦出现故障则所有算子均根据检查点重置状态，并且处理尚未保存到检查点中的记录。该解决方案十分直观，但是无法保证“同一时刻”。由于实现DAG中算子的任务分布在不同的物理节点，因此要在同一时刻保存所有算子的状态则要求所有节点的物理时钟绝对同步，然而绝对的时钟同步是不可能的。

#### 10.4.2 非迭代计算过程的容错

在某一时刻，流计算系统所处理的记录可以分为三种类型。

1. 已经处理完毕的记录，即所有算子均已处理该部分记录。
2. 正在处理的记录，即部分算子处理该部分记录。
3. 尚未处理的记录，即没有算子处理过该部分记录。

虽然绝对同步的时钟不存在，但是同一时刻保存所有算子状态到检查点的目的是区分第1种记录与后两种记录。Flink借鉴分布式系统中用于保存系统状态的Chandy-Lamport算法的思想，实现异步屏障快照（asynchronous barrier snapshotting, ABS）算法，所保存的快照即为检查点。异步屏障快照算法通过在输入数据中注入屏障并异步地保存快照，达到和在同一时刻保存所有算子状态到检查点相同的目的。

![image-20240623000736527](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240623000736527.png)

JobManager在输入记录中插入屏障（barrier），这些屏障与记录一起向下游计算任务流动，每个屏障指示检查点的ID。例如，ID为$n$表示屏障之前的记录均属于检查点$n$。屏障将无界数据中的记录分为属于当前检查点的记录和属于下一个检查点的记录。算子收到屏障后，便将算子当前的状态写入外部可靠的存储系统。

由于系统需要周期性地保存检查点，因此还需协调多个检查点。一种直观的方式是将属于检查点$n$的数据注入系统，收到屏障后保存当前的状态形成检查点$n$，然后将属于检查点$n+1$的数据注入系统。这种同步快照方式非常直观，检查点$n+1$和检查点$n$互不干扰。这种方式虽然简单，但是**缺点**明显：在检查点$n$的形成过程中，属于检查点$n+1$的数据需要等待进入系统，造成较高的延迟。为了避免同步快照导致的高延迟，Flink采用异步快照方式。在异步快照方式中，数据不断注入系统，实现算子的任务收到来自上游任务中所有标识为$n$的屏障（即屏障对齐）后保存其状态。随着记录的流动，所有算子保存的状态形成检查点$n$。值得指出的是，某一任务将标识为$n$的屏障对齐后，能够继续接收属于检查点$n+1$的记录。因此，同一时刻系统中的不同任务保存属于不同检查点的状态。与同步快照方式不同，异步快照方式中标识不同检查点的屏障可以同时在系统中出现，能够同时保存多个不同的检查点。

需要指出的是，此处描述的异步快照方式要求进行屏障对齐，但是经典的Chandy-Lamport算法并不要求进行屏障对齐。若不进行屏障对齐，则检查点中还需保存“超前”的记录。与对齐屏障的异步检查点相比，非对齐屏障的异步检查点有利于进一步降低延迟，但增加了检查点的大小。Flink自1.11版本开始支持非对齐屏障的异步检查点。

![image-20240623015132681](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240623015132681.png)

设置检查点后，基于检查点的恢复过程十分直观。当发生故障时，Flink选择最近完整的检查点$n$，将系统中每个算子的状态重置为检查点中保存的状态，并从数据源重新读取属于屏障$n$之后的记录。当然，该过程要求数据源具备一定的记忆功能。因此，Flink的容错机制能够满足准确一次的容错语义（无论是否发生了故障，结果都一致）。

#### 10.4.3 迭代计算过程的容错

迭代计算过程包含数据传递的环路。迭代反馈的数据和输入数据将继续进行新的计算，因而在该情况下仅靠屏障无法将属于检查点$n$和检查点$n+1$的记录区分。

根据Chandy-Lamport算法，反馈环路中的所有记录需要以日志形式保存。当故障发生后，系统需要根据最近的完整的检查点$n$重置各个算子的状态，还需重新读取属于屏障$n$之后的记录以及日志中的记录。目前迭代计算异步快照屏障的代码尚未并入正式版本，因而Flink的检查点仅适用于非迭代计算过程。

对于以DataSet编写的程序而言，Flink系统无法支持容错，一旦出现故障只能重新执行整个程序。

**从代码角度看应用与作业**

![image-20240623015953622](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20240623015953622.png)
